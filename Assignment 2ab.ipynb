{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carol Calin - 11394846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Increase max row display in pandas\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "# Set directory\n",
    "os.chdir(\"C:/Users/acali/machine learning/election_data\")\n",
    "# Import data set\n",
    "df = pd.read_csv(\"votes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new target variable in df\n",
    "# Variable 'target' receives value \"1\" if more than 50% of votes in the county went to Trump, 0 otherwise (meaning Clinton won)\n",
    "df['target'] = np.where(df['Trump']>=0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population2014</th>\n",
       "      <th>population2010</th>\n",
       "      <th>population_change</th>\n",
       "      <th>POP010210</th>\n",
       "      <th>AGE135214</th>\n",
       "      <th>age65plus</th>\n",
       "      <th>SEX255214</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>RHI325214</th>\n",
       "      <th>RHI425214</th>\n",
       "      <th>RHI525214</th>\n",
       "      <th>RHI625214</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>RHI825214</th>\n",
       "      <th>...</th>\n",
       "      <th>SBO001207</th>\n",
       "      <th>SBO315207</th>\n",
       "      <th>SBO115207</th>\n",
       "      <th>SBO215207</th>\n",
       "      <th>SBO515207</th>\n",
       "      <th>SBO415207</th>\n",
       "      <th>SBO015207</th>\n",
       "      <th>MAN450207</th>\n",
       "      <th>WTN220207</th>\n",
       "      <th>RTN130207</th>\n",
       "      <th>RTN131207</th>\n",
       "      <th>AFN120207</th>\n",
       "      <th>BPS030214</th>\n",
       "      <th>LND110210</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55395</td>\n",
       "      <td>54571</td>\n",
       "      <td>1.5</td>\n",
       "      <td>54571</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>51.4</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.027</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4067</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>598175</td>\n",
       "      <td>12003</td>\n",
       "      <td>88157</td>\n",
       "      <td>131</td>\n",
       "      <td>594.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200111</td>\n",
       "      <td>182265</td>\n",
       "      <td>9.8</td>\n",
       "      <td>182265</td>\n",
       "      <td>5.6</td>\n",
       "      <td>18.7</td>\n",
       "      <td>51.2</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.046</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19035</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1410273</td>\n",
       "      <td>0</td>\n",
       "      <td>2966489</td>\n",
       "      <td>17166</td>\n",
       "      <td>436955</td>\n",
       "      <td>1384</td>\n",
       "      <td>1589.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26887</td>\n",
       "      <td>27457</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>27457</td>\n",
       "      <td>5.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>46.6</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.045</td>\n",
       "      <td>46.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188337</td>\n",
       "      <td>6334</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>884.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22506</td>\n",
       "      <td>22919</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>22915</td>\n",
       "      <td>5.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.021</td>\n",
       "      <td>74.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1385</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124707</td>\n",
       "      <td>5804</td>\n",
       "      <td>10757</td>\n",
       "      <td>19</td>\n",
       "      <td>622.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57719</td>\n",
       "      <td>57322</td>\n",
       "      <td>0.7</td>\n",
       "      <td>57322</td>\n",
       "      <td>6.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.087</td>\n",
       "      <td>87.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>341544</td>\n",
       "      <td>0</td>\n",
       "      <td>319700</td>\n",
       "      <td>5622</td>\n",
       "      <td>20941</td>\n",
       "      <td>3</td>\n",
       "      <td>644.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10764</td>\n",
       "      <td>10915</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>10914</td>\n",
       "      <td>6.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>45.3</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.075</td>\n",
       "      <td>22.1</td>\n",
       "      <td>...</td>\n",
       "      <td>417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43810</td>\n",
       "      <td>3995</td>\n",
       "      <td>3670</td>\n",
       "      <td>1</td>\n",
       "      <td>622.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20296</td>\n",
       "      <td>20946</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>20947</td>\n",
       "      <td>6.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.012</td>\n",
       "      <td>53.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399132</td>\n",
       "      <td>56712</td>\n",
       "      <td>229277</td>\n",
       "      <td>11326</td>\n",
       "      <td>28427</td>\n",
       "      <td>2</td>\n",
       "      <td>776.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>115916</td>\n",
       "      <td>118586</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>118572</td>\n",
       "      <td>5.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.035</td>\n",
       "      <td>72.9</td>\n",
       "      <td>...</td>\n",
       "      <td>8713</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.7</td>\n",
       "      <td>2679991</td>\n",
       "      <td>0</td>\n",
       "      <td>1542981</td>\n",
       "      <td>13678</td>\n",
       "      <td>186533</td>\n",
       "      <td>114</td>\n",
       "      <td>605.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34076</td>\n",
       "      <td>34170</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>34215</td>\n",
       "      <td>5.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>52.3</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.020</td>\n",
       "      <td>56.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>667283</td>\n",
       "      <td>0</td>\n",
       "      <td>264650</td>\n",
       "      <td>7620</td>\n",
       "      <td>23237</td>\n",
       "      <td>8</td>\n",
       "      <td>596.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26037</td>\n",
       "      <td>25986</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25989</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>50.2</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.015</td>\n",
       "      <td>91.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>307439</td>\n",
       "      <td>62293</td>\n",
       "      <td>186321</td>\n",
       "      <td>7613</td>\n",
       "      <td>13948</td>\n",
       "      <td>2</td>\n",
       "      <td>553.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population2014  population2010  population_change  POP010210  AGE135214  \\\n",
       "0           55395           54571                1.5      54571        6.0   \n",
       "1          200111          182265                9.8     182265        5.6   \n",
       "2           26887           27457               -2.1      27457        5.7   \n",
       "3           22506           22919               -1.8      22915        5.3   \n",
       "4           57719           57322                0.7      57322        6.1   \n",
       "5           10764           10915               -1.4      10914        6.3   \n",
       "6           20296           20946               -3.1      20947        6.1   \n",
       "7          115916          118586               -2.3     118572        5.7   \n",
       "8           34076           34170               -0.3      34215        5.9   \n",
       "9           26037           25986                0.2      25989        4.8   \n",
       "\n",
       "   age65plus  SEX255214  White  Black  RHI325214  RHI425214  RHI525214  \\\n",
       "0       13.8       51.4  0.779  0.187        0.5        1.1        0.1   \n",
       "1       18.7       51.2  0.871  0.096        0.7        0.9        0.1   \n",
       "2       16.5       46.6  0.502  0.476        0.6        0.5        0.2   \n",
       "3       14.8       45.9  0.763  0.221        0.4        0.2        0.1   \n",
       "4       17.0       50.5  0.960  0.018        0.6        0.3        0.1   \n",
       "5       14.9       45.3  0.269  0.701        0.8        0.3        0.7   \n",
       "6       18.0       53.6  0.539  0.440        0.4        0.9        0.0   \n",
       "7       16.0       51.8  0.758  0.211        0.5        0.9        0.1   \n",
       "8       18.3       52.3  0.583  0.395        0.3        0.8        0.1   \n",
       "9       20.9       50.2  0.930  0.046        0.5        0.3        0.0   \n",
       "\n",
       "   RHI625214  Hispanic  RHI825214   ...    SBO001207  SBO315207  SBO115207  \\\n",
       "0        1.8     0.027       75.6   ...         4067       15.2        0.0   \n",
       "1        1.6     0.046       83.0   ...        19035        2.7        0.4   \n",
       "2        0.9     0.045       46.6   ...         1667        0.0        0.0   \n",
       "3        0.9     0.021       74.5   ...         1385       14.9        0.0   \n",
       "4        1.2     0.087       87.8   ...         4458        0.0        0.0   \n",
       "5        1.1     0.075       22.1   ...          417        0.0        0.0   \n",
       "6        0.8     0.012       53.1   ...         1769        0.0        0.0   \n",
       "7        1.7     0.035       72.9   ...         8713        7.2        0.0   \n",
       "8        1.1     0.020       56.8   ...         1981        0.0        0.0   \n",
       "9        1.6     0.015       91.6   ...         2180        0.0        0.0   \n",
       "\n",
       "   SBO215207  SBO515207  SBO415207  SBO015207  MAN450207  WTN220207  \\\n",
       "0        1.3        0.0        0.7       31.7          0          0   \n",
       "1        1.0        0.0        1.3       27.3    1410273          0   \n",
       "2        0.0        0.0        0.0       27.0          0          0   \n",
       "3        0.0        0.0        0.0        0.0          0          0   \n",
       "4        0.0        0.0        0.0       23.2     341544          0   \n",
       "5        0.0        0.0        0.0       38.8          0          0   \n",
       "6        3.3        0.0        0.0        0.0     399132      56712   \n",
       "7        1.6        0.0        0.5       24.7    2679991          0   \n",
       "8        0.0        0.0        0.0       29.3     667283          0   \n",
       "9        0.0        0.0        0.0       14.5     307439      62293   \n",
       "\n",
       "   RTN130207  RTN131207  AFN120207  BPS030214  LND110210  target  \n",
       "0     598175      12003      88157        131     594.44       1  \n",
       "1    2966489      17166     436955       1384    1589.78       1  \n",
       "2     188337       6334          0          8     884.88       1  \n",
       "3     124707       5804      10757         19     622.58       1  \n",
       "4     319700       5622      20941          3     644.78       1  \n",
       "5      43810       3995       3670          1     622.81       0  \n",
       "6     229277      11326      28427          2     776.83       1  \n",
       "7    1542981      13678     186533        114     605.87       1  \n",
       "8     264650       7620      23237          8     596.53       1  \n",
       "9     186321       7613      13948          2     553.70       1  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Selecting the target variables\n",
    "df1 = df[['population2014', 'population2010', 'population_change', 'POP010210', 'AGE135214', 'age65plus', 'SEX255214', 'White', 'Black','RHI325214', 'RHI425214', 'RHI525214', 'RHI625214', 'Hispanic','RHI825214','POP715213', 'POP645213', 'NonEnglish','Edu_highschool', 'Edu_batchelors', 'VET605213', 'LFE305213', 'HSG010214', 'HSG445213', 'HSG096213', 'HSG495213', 'HSD410213', 'HSD310213', 'Income', 'INC110213', 'Poverty', 'BZA010213', 'BZA110213', 'BZA115213', 'NES010213', 'SBO001207', 'SBO315207', 'SBO115207', 'SBO215207', 'SBO515207', 'SBO415207', 'SBO015207', 'MAN450207', 'WTN220207', 'RTN130207', 'RTN131207', 'AFN120207', 'BPS030214', 'LND110210', 'target' ]]\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2527\n",
      "0     585\n",
      "Name: target, dtype: int64\n",
      "(3112, 50)\n"
     ]
    }
   ],
   "source": [
    "# Checking the header of the variable to see whether the selection worked\n",
    "print(df1['target'].value_counts())\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "population2014       3.276072e+05\n",
       "population2010       3.143304e+05\n",
       "population_change    4.195582e+00\n",
       "POP010210            3.143192e+05\n",
       "AGE135214            1.183065e+00\n",
       "age65plus            4.387073e+00\n",
       "SEX255214            2.205303e+00\n",
       "White                1.578842e-01\n",
       "Black                1.448295e-01\n",
       "RHI325214            6.546744e+00\n",
       "RHI425214            2.549237e+00\n",
       "RHI525214            4.071945e-01\n",
       "RHI625214            1.354658e+00\n",
       "Hispanic             1.353501e-01\n",
       "RHI825214            1.963027e+01\n",
       "                         ...     \n",
       "SBO001207            3.169620e+04\n",
       "SBO315207            6.914713e+00\n",
       "SBO115207            2.861644e+00\n",
       "SBO215207            2.550786e+00\n",
       "SBO515207            3.504189e-01\n",
       "SBO415207            6.253284e+00\n",
       "SBO015207            1.284299e+01\n",
       "MAN450207            5.732086e+06\n",
       "WTN220207            7.332659e+06\n",
       "RTN130207            4.155059e+06\n",
       "RTN131207            5.424050e+03\n",
       "AFN120207            8.889694e+05\n",
       "BPS030214            1.303162e+03\n",
       "LND110210            1.303292e+03\n",
       "target               3.907606e-01\n",
       "Length: 50, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing for data preprocessing, checking out the standard deviations of the variables\n",
    "df1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Create target value\n",
    "\n",
    "X = df1.iloc[:,:-1]\n",
    "y = df1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3112, 49)\n",
      "(3112,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2334, 49) (778, 49) (2334,) (778,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=20, random_state=20, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('linearsvc', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'linearsvc__C': [0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "pipe = make_pipeline(LinearSVC())\n",
    "param_grid = {'linearsvc__C':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=20, test_size=0.2, random_state=20)\n",
    "\n",
    "grid_pipe = GridSearchCV(pipe,param_grid, cv = cv)\n",
    "\n",
    "grid_pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'loss', 'max_iter', 'multi_class', 'penalty', 'random_state', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearSVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.78\n",
      "Test set score: 0.80\n",
      "Best parameters: {'linearsvc__C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Finding the optimal value for the C parameter of the LinearSVC \n",
    "\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_pipe.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid_pipe.score(X_test, y_test))) \n",
    "print(\"Best parameters: {}\".format(grid_pipe.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scaler Test score: 0.77\n"
     ]
    }
   ],
   "source": [
    "linearpipe = make_pipeline(LinearSVC(C=0.01, random_state = 42))\n",
    "linearpipe.fit(X_train, y_train)\n",
    "\n",
    "print(\"No scaler Test score: {:.2f}\".format(linearpipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test score: 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score Robust: 0.92\n",
      "Test score Standard Scaler: 0.92\n",
      "Test score Min Max Scaler: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Pipeline LinearSVC with scalers\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "linearpipe1 = make_pipeline(RobustScaler(),LinearSVC(C=0.01, random_state = 100))\n",
    "linearpipe1.fit(X_train, y_train)\n",
    "print(\"Test score Robust: {:.2f}\".format(linearpipe1.score(X_test, y_test)))\n",
    "\n",
    "linearpipe2 = make_pipeline(StandardScaler(), LinearSVC(C=0.01, random_state = 100))\n",
    "linearpipe2.fit(X_train, y_train)\n",
    "print(\"Test score Standard Scaler: {:.2f}\".format(linearpipe2.score(X_test, y_test)))\n",
    "\n",
    "linearpipe3 = make_pipeline(MinMaxScaler(), LinearSVC(C=0.01, random_state = 100))\n",
    "linearpipe3.fit(X_train, y_train)\n",
    "print(\"Test score Min Max Scaler: {:.2f}\".format(linearpipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score improvement from 0.77 to 0.92 with the Min Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score Robust, c = 0.001, not optimal according to gridsearch: 0.85\n",
      "Test score Standard Scaler, c = 0.001, not optimal according to gridsearch: 0.84\n",
      "Test score Min Max Scaler, c = 0.001, not optimal according to gridsearch: 0.90\n",
      "Test score no scaler and C = 0.001: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Pipeline LinearSVC with scalers, different C than the one recommended by grid search\n",
    "\n",
    "linearpipe4 = make_pipeline(RobustScaler(), LinearSVC(C=1000, random_state = 100))\n",
    "linearpipe4.fit(X_train, y_train)\n",
    "print(\"Test score Robust, c = 0.001, not optimal according to gridsearch: {:.2f}\".format(linearpipe4.score(X_test, y_test)))\n",
    "\n",
    "linearpipe5 = make_pipeline(StandardScaler(), LinearSVC(C=1000, random_state = 100))\n",
    "linearpipe5.fit(X_train, y_train)\n",
    "print(\"Test score Standard Scaler, c = 0.001, not optimal according to gridsearch: {:.2f}\".format(linearpipe5.score(X_test, y_test)))\n",
    "\n",
    "linearpipe6 = make_pipeline(MinMaxScaler(), LinearSVC(C=1000, random_state = 100))\n",
    "linearpipe6.fit(X_train, y_train)\n",
    "print(\"Test score Min Max Scaler, c = 0.001, not optimal according to gridsearch: {:.2f}\".format(linearpipe6.score(X_test, y_test)))\n",
    "\n",
    "# Pipeline LinearSVC no scaler, C different than found\n",
    "\n",
    "linearpipe7 = make_pipeline(LinearSVC(C=1000, random_state = 100))\n",
    "linearpipe7.fit(X_train, y_train)\n",
    "print(\"Test score no scaler and C = 0.001: {:.2f}\".format(linearpipe7.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that C indeed has an influence on the accuracy of the models. Both the robust and the standard scaled data is affected, while the min max scaler does not notice any performance drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.87\n",
      "Test set score: 0.88\n",
      "Best parameters: {'logisticregression__C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "pipe = make_pipeline(LogisticRegression())\n",
    "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100]} \n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=20, test_size=0.2, random_state=42)\n",
    "# Chose the stratified shuffle because it results in stratified randomized folds which retain the sample percentage for each class \n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=cv) \n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "# Finding the optimal value for the C parameter of the logistic regression\n",
    "\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_)) \n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test))) \n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Pipeline logistic regression no data scaling\n",
    "\n",
    "pipe1 = make_pipeline(LogisticRegression(C=10, random_state = 1642))\n",
    "pipe1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test score: {:.2f}\".format(pipe1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score Robust, c = 0.001, not optimal according to gridsearch: 0.87\n",
      "Test score Standard Scaler, c = 0.001, not optimal according to gridsearch: 0.88\n",
      "Test score Min Max Scaler, c = 0.001, not optimal according to gridsearch: 0.81\n",
      "Test score no scaler and C = 0.001: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Pipeline logistic regression with scalers, different C than the one recommended by grid search\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "pipe4 = make_pipeline(RobustScaler(), LogisticRegression(C=0.001, random_state = 1642))\n",
    "pipe4.fit(X_train, y_train)\n",
    "print(\"Test score Robust, c = 0.001, not optimal according to gridsearch: {:.2f}\".format(pipe4.score(X_test, y_test)))\n",
    "\n",
    "pipe5 = make_pipeline(StandardScaler(), LogisticRegression(C=0.001, random_state = 1642))\n",
    "pipe5.fit(X_train, y_train)\n",
    "print(\"Test score Standard Scaler, c = 0.001, not optimal according to gridsearch: {:.2f}\".format(pipe5.score(X_test, y_test)))\n",
    "\n",
    "pipe6 = make_pipeline(MinMaxScaler(), LogisticRegression(C=0.001, random_state = 1642))\n",
    "pipe6.fit(X_train, y_train)\n",
    "print(\"Test score Min Max Scaler, c = 0.001, not optimal according to gridsearch: {:.2f}\".format(pipe6.score(X_test, y_test)))\n",
    "\n",
    "pipe7 = make_pipeline(LogisticRegression(C=0.001, random_state = 1642))\n",
    "pipe7.fit(X_train, y_train)\n",
    "print(\"Test score no scaler and C = 0.001: {:.2f}\".format(pipe7.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score Robust: 0.92\n",
      "Test score Standard Scaler: 0.93\n",
      "Test score Min Max Scaler: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Pipeline logistic regression with scalers\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "pipe1 = make_pipeline(RobustScaler(), LogisticRegression(C=10, random_state = 1879))\n",
    "pipe1.fit(X_train, y_train)\n",
    "print(\"Test score Robust: {:.2f}\".format(pipe1.score(X_test, y_test)))\n",
    "\n",
    "pipe2 = make_pipeline(StandardScaler(), LogisticRegression(C=10, random_state = 1879))\n",
    "pipe2.fit(X_train, y_train)\n",
    "print(\"Test score Standard Scaler: {:.2f}\".format(pipe2.score(X_test, y_test)))\n",
    "\n",
    "pipe3 = make_pipeline(MinMaxScaler(), LogisticRegression(C=10, random_state = 1879))\n",
    "pipe3.fit(X_train, y_train)\n",
    "print(\"Test score Min Max Scaler: {:.2f}\".format(pipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that \n",
    "1) the base test score of 0.88 is improved if scalers are used on the data, from 0.88 to 0.93 with the Robust scaler, while the best test score is achieved with the Standard and Min Max scalers 0.93\n",
    "2) if I use different values of C than the one found by GridSearchCV, the performance of the Logistic Regression drops, with the lowest score being 0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (7624, 281)\n",
      "Train shape (52397, 281)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"C:/Users/acali/machine learning/ml_data\")\n",
    "train = pd.read_csv(\"webStats_train.csv\", header = None)\n",
    "\n",
    "test_all = []\n",
    "for file in glob.glob(\"webStats_test-*.csv\"):\n",
    "    test_all.append(pd.read_csv(file,  header = None))\n",
    "\n",
    "test = pd.concat(test_all, axis = 0)\n",
    "print (\"Test shape:\", test.shape)\n",
    "print (\"Train shape\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:-1]\n",
    "y_train = train.iloc[:,-1]\n",
    "X_test = test.iloc[:,:-1]\n",
    "y_test = test.iloc[:,-1]\n",
    "\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         1.0\n",
       "4        27.0\n",
       "5         0.0\n",
       "6         0.0\n",
       "7        27.0\n",
       "8         9.0\n",
       "9         9.0\n",
       "10        0.0\n",
       "11        0.0\n",
       "12        2.0\n",
       "13        0.0\n",
       "14       13.0\n",
       "15       15.0\n",
       "16        3.0\n",
       "17       15.0\n",
       "18       13.0\n",
       "19        1.0\n",
       "20       21.0\n",
       "21        1.0\n",
       "22       21.0\n",
       "23        1.0\n",
       "24        3.0\n",
       "25        3.0\n",
       "26        3.0\n",
       "27        3.0\n",
       "28        2.0\n",
       "29        2.0\n",
       "         ... \n",
       "52367     0.0\n",
       "52368     0.0\n",
       "52369     0.0\n",
       "52370     0.0\n",
       "52371     1.0\n",
       "52372     0.0\n",
       "52373     0.0\n",
       "52374     0.0\n",
       "52375     0.0\n",
       "52376     0.0\n",
       "52377     0.0\n",
       "52378     0.0\n",
       "52379     2.0\n",
       "52380     0.0\n",
       "52381     1.0\n",
       "52382     0.0\n",
       "52383     0.0\n",
       "52384     0.0\n",
       "52385     0.0\n",
       "52386     0.0\n",
       "52387     0.0\n",
       "52388     0.0\n",
       "52389     0.0\n",
       "52390     0.0\n",
       "52391     0.0\n",
       "52392     0.0\n",
       "52393     0.0\n",
       "52394     0.0\n",
       "52395     0.0\n",
       "52396     0.0\n",
       "Name: 280, Length: 52397, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train>2] = 'Very-Popular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train==0] = 'Not-Popular'\n",
    "y_train[y_train==1] = 'Somewhat-Popular'\n",
    "y_train[y_train==2] = 'Very-Popular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(y_test)\n",
    "\n",
    "y_test[y_test>2] = 'Very-Popular'\n",
    "\n",
    "y_test[y_test==0] = 'Not-Popular'\n",
    "y_test[y_test==1] = 'Somewhat-Popular'\n",
    "y_test[y_test==2] = 'Very-Popular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.55\n",
      "Test set score: 0.70\n",
      "Best parameters: {'linearsvc__C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Finding the optimal value for the C parameter of the LinearSVC \n",
    "\n",
    "linearsvcpipe = make_pipeline(LinearSVC())\n",
    "param_grid = {'linearsvc__C':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=20)\n",
    "\n",
    "grid_pipe = GridSearchCV(linearsvcpipe,param_grid, cv = 2)\n",
    "grid_pipe.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_pipe.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid_pipe.score(X_test, y_test))) \n",
    "print(\"Best parameters: {}\".format(grid_pipe.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scaler LinearSVC test accuracy: 0.32\n"
     ]
    }
   ],
   "source": [
    "testpipe1 = make_pipeline(LinearSVC(C=10, random_state = 42))\n",
    "testpipe1.fit(X_train, y_train)\n",
    "\n",
    "print(\"No scaler LinearSVC test accuracy: {:.2f}\".format(testpipe1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score LinearSVC MaxAbsScaler: 0.78\n",
      "Test score LinearSVC Standard Scaler: 0.75\n",
      "Test score LinearSVC Min Max Scaler: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Pipeline LinearSVC with scalers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "linearpipe1 = make_pipeline(MaxAbsScaler(),LinearSVC(C=10, random_state = 100))\n",
    "linearpipe1.fit(X_train, y_train)\n",
    "print(\"Test score LinearSVC MaxAbsScaler: {:.2f}\".format(linearpipe1.score(X_test, y_test)))\n",
    "\n",
    "linearpipe2 = make_pipeline(StandardScaler(), LinearSVC(C=10, random_state = 100))\n",
    "linearpipe2.fit(X_train, y_train)\n",
    "print(\"Test score LinearSVC Standard Scaler: {:.2f}\".format(linearpipe2.score(X_test, y_test)))\n",
    "\n",
    "linearpipe3 = make_pipeline(MinMaxScaler(), LinearSVC(C=10, random_state = 100))\n",
    "linearpipe3.fit(X_train, y_train)\n",
    "print(\"Test score LinearSVC Min Max Scaler: {:.2f}\".format(linearpipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpipe2 = make_pipeline(KNeighborsClassifier(n_neighbors=10))\n",
    "testpipe2.fit(X_train, y_train)\n",
    "\n",
    "print(\"No scaler Neighbors test accuracy: {:.2f}\".format(testpipe2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines Neighbors with scalers\n",
    "\n",
    "neighborpipe1 = make_pipeline(MaxAbsScaler(), KNeighborsClassifier(n_neighbors = 10))\n",
    "neighborpipe1.fit(X_train, y_train)\n",
    "print(\"Test score KNN (10) MaxAbsScaler: {:.2f}\".format(neighborpipe1.score(X_test, y_test)))\n",
    "\n",
    "neighborpipe2 = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors = 10))\n",
    "neighborpipe2.fit(X_train, y_train)\n",
    "print(\"Test score KNN (10) Standard Scaler: {:.2f}\".format(neighborpipe2.score(X_test, y_test)))\n",
    "\n",
    "neighborpipe3 = make_pipeline(MinMaxScaler(), KNeighborsClassifier(n_neighbors = 10))\n",
    "neighborpipe3.fit(X_train, y_train)\n",
    "print(\"Test score KNN (10) Min Max Scaler: {:.2f}\".format(neighborpipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scaler RandomForest (n_estimators = 100) test accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "testpipe3 = make_pipeline(RandomForestClassifier(n_estimators=100))\n",
    "testpipe3.fit(X_train, y_train)\n",
    "\n",
    "print(\"No scaler RandomForest (n_estimators = 100) test accuracy: {:.2f}\".format(testpipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score RandomForest MaxAbsScaler: 0.80\n",
      "Test score RandomForest Standard Scaler: 0.81\n",
      "Test score RandomForest Min Max Scaler: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Pipelines RandomForestClassifier with scalers\n",
    "\n",
    "forestpipe1 = make_pipeline(MaxAbsScaler(), RandomForestClassifier(n_estimators = 100))\n",
    "forestpipe1.fit(X_train, y_train)\n",
    "print(\"Test score RandomForest MaxAbsScaler: {:.2f}\".format(forestpipe1.score(X_test, y_test)))\n",
    "\n",
    "forestpipe2 = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 100))\n",
    "forestpipe2.fit(X_train, y_train)\n",
    "print(\"Test score RandomForest Standard Scaler: {:.2f}\".format(forestpipe2.score(X_test, y_test)))\n",
    "\n",
    "forestpipe3 = make_pipeline(MinMaxScaler(), RandomForestClassifier(n_estimators = 100))\n",
    "forestpipe3.fit(X_train, y_train)\n",
    "print(\"Test score RandomForest Min Max Scaler: {:.2f}\".format(forestpipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score RandomForest MaxAbsScaler: 0.80\n",
      "Test score RandomForest Standard Scaler: 0.81\n",
      "Test score RandomForest Min Max Scaler: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Pipelines RandomForestClassifier with scalers\n",
    "\n",
    "forestpipe1 = make_pipeline(MaxAbsScaler(), RandomForestClassifier(n_estimators = 100))\n",
    "forestpipe1.fit(X_train, y_train)\n",
    "print(\"Test score RandomForest MaxAbsScaler: {:.2f}\".format(forestpipe1.score(X_test, y_test)))\n",
    "\n",
    "forestpipe2 = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 100))\n",
    "forestpipe2.fit(X_train, y_train)\n",
    "print(\"Test score RandomForest Standard Scaler: {:.2f}\".format(forestpipe2.score(X_test, y_test)))\n",
    "\n",
    "forestpipe3 = make_pipeline(MinMaxScaler(), RandomForestClassifier(n_estimators = 100))\n",
    "forestpipe3.fit(X_train, y_train)\n",
    "print(\"Test score RandomForest Min Max Scaler: {:.2f}\".format(forestpipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the LinearSVC test accuracy was low, and the scaling of the data more than doubled the test accuracy of the model\n",
    "from 0.32 to 0.78 with the MaxAbsScaler and the MinMaxScaler.\n",
    "\n",
    "The KNN test accuracy was quite high from the beggining, with a value of 0.76 for the 10 closest neighbors, while scaling the data with any of the methods did not improve the test accuracy but even lowered it by 0.01.\n",
    "\n",
    "Finally, the RandomForestClassifier had an impressive test accuracy from the beggining, scoring 0.81. After scaling, no significant change can be observed, except for the MaxAbsScaler which reduced accuracy by 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nan_to_data(train_inputs, miss_prob=0.2):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Randomly flips a numpy ndarray entry to NaN with a supplied \n",
    "\n",
    "    probability.\n",
    "\n",
    "    \n",
    "\n",
    "    WARNING: Do not try to add missing values to labels. This is \n",
    "\n",
    "    not unsupervised learning.\n",
    "\n",
    "\n",
    "\n",
    "        :param train_inputs: Numpy ndarray of dims (num_examples, feature_dims)\n",
    "\n",
    "        :param miss_prob=0.2: Probability that a bit is flipped to NaN. \n",
    "\n",
    "    \"\"\"     \n",
    "\n",
    "    mask = np.random.choice(2, size=train_inputs.shape, p=[miss_prob,1-miss_prob]).astype(bool)\n",
    "\n",
    "    input_shape = train_inputs.shape\n",
    "\n",
    "\n",
    "\n",
    "    #Flatten Inputs and Mask\n",
    "\n",
    "    train_inputs = train_inputs.ravel()\n",
    "\n",
    "    mask = mask.ravel()\n",
    "\n",
    "    train_inputs[~mask] = np.nan\n",
    "\n",
    "    \n",
    "\n",
    "    # reshape inputs back to the original shape.\n",
    "\n",
    "    missing_train_inputs = np.reshape(train_inputs, newshape=input_shape)\n",
    "\n",
    "    \n",
    "\n",
    "    return missing_train_inputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.79550e+04,  2.81220e+04, -6.00000e-01, ...,  3.09800e+04,\n",
       "         3.00000e+01,  1.31395e+03],\n",
       "       [         nan,  1.06130e+04, -1.50000e+00, ...,          nan,\n",
       "         5.40000e+01,          nan],\n",
       "       [ 1.93930e+04,  1.98170e+04, -2.10000e+00, ...,  1.52660e+04,\n",
       "         5.00000e+00,  4.43630e+02],\n",
       "       ...,\n",
       "       [ 2.91140e+04,  2.84110e+04,  2.50000e+00, ...,  2.49610e+04,\n",
       "         2.70000e+01,  6.46510e+02],\n",
       "       [ 1.22640e+04,          nan, -5.70000e+00, ...,          nan,\n",
       "                 nan,  7.68150e+02],\n",
       "       [ 4.68196e+05,  4.67031e+05,  2.00000e-01, ...,  7.84291e+05,\n",
       "         9.56000e+02,  7.78390e+02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_nan_to_data(np.array(X_train), miss_prob = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.impute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-698bb77ab43a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxAbsScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.impute'"
     ]
    }
   ],
   "source": [
    "# Pipeline LinearSVC with missing data and scalers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "impute_mean = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
    "impute_mean.fit(X_train)\n",
    "\n",
    "\n",
    "# linearpipe1 = make_pipeline(MaxAbsScaler(),LinearSVC(C=10, random_state = 100))\n",
    "# linearpipe1.fit(X_train, y_train)\n",
    "# print(\"Test score LinearSVC MaxAbsScaler: {:.2f}\".format(linearpipe1.score(X_test, y_test)))\n",
    "\n",
    "# linearpipe2 = make_pipeline(StandardScaler(), LinearSVC(C=10, random_state = 100))\n",
    "# linearpipe2.fit(X_train, y_train)\n",
    "# print(\"Test score LinearSVC Standard Scaler: {:.2f}\".format(linearpipe2.score(X_test, y_test)))\n",
    "\n",
    "# linearpipe3 = make_pipeline(MinMaxScaler(), LinearSVC(C=10, random_state = 100))\n",
    "# linearpipe3.fit(X_train, y_train)\n",
    "# print(\"Test score LinearSVC Min Max Scaler: {:.2f}\".format(linearpipe3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My time management was awful, realized too late that I need to update my conda to use sklearn.impute, ops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
